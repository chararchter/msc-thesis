
Testējot multilingual BERT un XLM-RoBERTa daudzvalodu jēdzientelpas lietotāju nodomu noteikšanā piecās dažādās valodās tika konstatēts, ka (modelim) bija visaugstākā precizitāte (valodās) valodās ar ()\%. (Modelis) arī darbojās labi ar kopējo precizitāti ()\%. Rezultāti liecina, ka daudzvalodu vārdu iegulšanas izmantošana var būt efektīva nodomu noteikšanai vairākās valodās, un modeļa izvēle var būtiski ietekmēt klasifikācijas uzdevuma precizitāti.

Modeļu precizitāte katrai valodai bija atšķirīga, ar zemāko precizitāti (valodā) valodā, un augstāko precizitāti (valodā) valodā, kas bija sagaidāms ņemot vērā datu kopas uz kurām tika apmācīti multilingual BERT un XLM-RoBERTa modeļi. 


Kopumā paredzams, ka nolūku klasifikācijas modeļu precizitāte būs augstāka oriģinālajiem ievades datiem latviešu, igauņu, krievu un lietuviešu valodā, salīdzinot ar to pašu ievades datu mašīnu, kas tulkota angļu valodā. Tas ir tāpēc, ka mašīntulkošana rada papildu trokšņus un kļūdas, kas var ietekmēt ievades datu kvalitāti un klasifikācijas modeļu veiktspēju. Turklāt mašīntulkošanas rezultātā dažkārt var tikt zaudētas svarīgas nianses un katrai valodai raksturīgā semantiskā informācija, kas var vēl vairāk pasliktināt ievades datu kvalitāti un apgrūtināt precīzu nolūku klasificēšanu.

Tomēr precīza modeļu veiktspēja var atšķirties atkarībā no vairākiem faktoriem, piemēram, mašīntulkošanas kvalitātes, ievades vaicājumu sarežģītības un izmantoto daudzvalodu vārdu iegulšanas specifiskajām īpašībām. Tāpēc ir svarīgi novērtēt modeļu veiktspēju gan ar oriģinālajiem, gan mašīntulkotajiem ievades datiem un salīdzināt rezultātus, lai labāk izprastu modeļu stiprās puses un ierobežojumus daudzvalodu nolūku klasifikācijas uzdevumiem.
