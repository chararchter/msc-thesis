Daudzvalodu nodomu noteikšana ir lietotāja vaicājumu nolūka identificēšana dažādās valodās. Šajā sadaļā tiks dots ieskats trīs pieejām daudzvalodu nodomu noteikšanas modeļu apmācībai un testēšanai, tās pamatojot ar pieejamo teorētisko literatūru par šo tēmu:
\begin{enumerate}
	\item apmācība vienā valodā, un testēšana tajā pašā valodā, piemēram, apmācība latviešu valodā, un testēšana arī latviešu valodā;
	\item apmācība uz visām valodām kopā, testēšana vienā valodā, piemēram, apmācība par datu kopu, kura ir angļu, latviešu, krievu, igauņu, lietuviešu datu kopas apvienotas vienā, testēšana latviešu valodā;
	\item apmācība angļu valodā, testēšana ne-angļu valodā.
\end{enumerate}

Katrai no trim pieejām ir savas priekšrocības un ierobežojumi, un pieejas izvēle ir atkarīga no konkrētajām uzdevuma prasībām. Apmācība un testēšana vienā un tajā pašā valodā var nodrošināt augstāku precizitāti, savukārt, apmācot visas valodas kopā, var izveidot vienu modeli vairākām valodām, taču dažās valodās var būt zemāka precizitāte. Apmācība angļu valodā un testēšana valodās, kas nav angļu valoda, ir noderīgas, ja ir ierobežoti resursi citām valodām un ir sagaidāms, ka modelis labi darbosies angļu valodā. Pieejas izvēlei jābūt balstītai uz uzdevuma īpašajām prasībām un resursiem.



Cilvēki sagaida precīzu mijiedarbību ar virtuālajiem asistentiem neatkarīgi no viņu lietotās valodas, tomēr mērogot (\textit{scaling}) nodomu noteikšanas plūsmu (\textit{pipeline}) uz vairākām valodām ir izaicinājums \cite{de-bruyn-2022}. 



Mēs izmantojam lielajiem modeļiem (\textit{large language model}) raksturīgo daudzvalodu aspektu daudzvalodu nodomu noteikšanas uzdevumiem \cite{de-bruyn-2022}.




Tika parādīts, ka tas veiksmīgi realizē nodomu noteikšanu, sasniedzot 93.4\% vidējo precizitāti uz MASSIVE datu kopas, kas satur (angļu tekstu iztulkotu 51 valodās) paralēlus (katrs izteikums tulkots 51 valodā) anotētus datus \cite{de-bruyn-2022}.



Atrada, ka modeļu precizitāti var uzlabot mākslīgi palielinot treniņkopas izmēru. Tomēr treniņkopas palielināšana palielināja arī pārklājumu ar testa kopu, kas pārvērtēja (\textit{overestimating}) patieso precizitāti \cite{de-bruyn-2022}.




Ir divas iespējas: viens modelis katrai valodai vai kopīgs modelis visām valodām. Katrai valodai savs modelis labi darbojas resursietilpīgās valodās, piemēram, angļu valodā. Tomēr maz-resursu valodas (valodas, kurās ir mazāk resursu) gūst labumu no starp-valodu zināšanu pārneses (\textit{cross-lingual knowledge transfer}), kas raksturīga vienam modelim \cite{de-bruyn-2022}.

Tipisks daudzvalodu nodomu noteikšanas risinājums ir transformeru daudzvalodu modeļu izmantošana, piemēram, mBert un XLM-RoBERTa. Šie modeļi ir līdzīgi monolingvāliem modeļiem, izņemot to ka tiek trenēti uz daudzvalodu datu kopām (atšķirībā no monolingvāliem modeļiem, daudzvalodu modeļi tiek trenēti uz daudzvalodu datu kopām) \cite{de-bruyn-2022}. 

Izmantojot kopīgu modeli angļu, hindi un bengali valodu mBERT jēdzientelpām precizitāte palielinās par ~2\% nekā atsevišķi trenējot katrā valodā (salīdzinot ar individuāliem nodomu noteikšanas modeļiem) \cite{firdaus2023}.



Izplatīta stratēģija šīs problēmas (maz treniņdatu) risināšanai ir ievākt vairāk datu un apmācīt katru vienvalodu nodomu noteikšanas modeli atsevišķi, taču tas ir dārgi un resursietilpīgi. Izmantojot vienu daudzvalodu modeli zināšanas no liel-resursu valodas tiek pārnestas uz mazresursu mērķvalodu \cite{liu2020}.

Visbeidzot, būtu svarīgi izpētīt, kā virtuālais asistents tiek galā ar jauktu valodu vaicājumiem (\textit{code switching}), kas ir izplatīti daudzvalodu vidēs, piemēram, kombinācija latviešu-angļu. Tas ietver pieeju izpēti vairāku valodu identificēšanai un atdalīšanai vienā izteikumā, kā arī efektīvi pielietotas daudzvalodu jēdzientelpas. Piemēram, pētījumā datu kopa, kas sastāv tikai no jauktu angļu un hindi valodu vaicājumiem, bija ar ~2\% zemāku precizitāti (F1 score) nekā angļu, hindi un jauktu valodu datu kopa, ar ELMO jēdzientelpām \cite{jayarao2018}.

Vēl viens jauktu valodu paņēmiens ir aizvietot izvēlētus vārdus ar to tulkojumiem maz-resursu valodām. Pētījumā salīdzinot modeļa trenēšanu tikai uz angļu datu kopas un testēšanu uz spāņu datiem ar modeļa trenēšanu uz jauktiem angļu un spāņu valodu vaicājumiem ar multilingual BERT jēdzientelpām precizitāte uzlabojās no 73.7\% uz 86.5\%, ar XLM jēdzientelpām no 60.8\% uz 83.9\% \cite{liu2020}. Jauktu valodu vaicājumi tika ģenerēti automātiski aizvietojot vārdus, kas izvēlēti balstoties uz uzmanības slāņa (\textit{attention layer}) aprēķinātajiem rādītājiem (scores) uz angļu valodas modeļa, ar to tulkojumiem bilingvālā vārdnīcā \cite{liu2020}. 
% table 2 





\section{Trenēšana un testēšana vienā valodā}

Modeļa apmācība un testēšana vienā un tajā pašā valodā ir piemērota, ja paredzams, ka nodomu noteikšanas modelis konkrētajā valodā darbosies ar labi precizitāti. Vairāki pētījumi ir parādījuši, ka apmācība un testēšana vienā un tajā pašā valodā var nodrošināt lielāku nodomu noteikšanas modeļu precizitāti. Piemēram, savā pētījumā par nodomu noteikšanu (valodā) valodā autors (gads) atklāja, ka uz tās pašas valodas trenēta modeļa izmantošana uzlaboja klasifikācijas precizitāti. Līdzīgi savā pētījumā par nodomu noteikšanu (valodā) valodā autors (gads) atklāja, ka apmācība un testēšana vienā un tajā pašā valodā nodrošināja lielāku precizitāti, salīdzinot ar apmācību vairākās valodās. Autors (gads) veica eksperimentu, kurā apmācīja un pārbaudīja nodomu noteikšanas modeļus (datu kopa) datu kopā (skaits) dažādās valodās: (valodu uzskaitījums). Rezultāti parādīja, ka apmācība uz vienas valodas datu kopas ievērojami uzlaboja modeļa veiktspēju salīdzinot ar apmācību uz vairākām valodām vienlaicīgi. Turklāt autors (gads) novērtēja dažādu pārsūtīšanas mācīšanās paņēmienu efektivitāti daudzvalodu nodomu noteikšanai un noteica, ka iepriekš apmācīta modeļa pietrenēšana (\textit{fine-tuning}) mērķa valodas datu kopā pārspēja citas metodes.

Priekšrocības šādai pieejai ir iespēja ieviest nepārtrauktu attīstību (\textit{continuous integration}), kurā ienākošie lietotāju ievades teksti un nodomi tiek izmantoti papildus apmācībai, izolējot efektus vienā valodā. Trūkums ir resursietilpīgāka vairāku modeļu trenēšana un uzturēšana.

\section{Trenēšana uz visām valodām, testēšana vienā valodā}

Otrā pieeja ir modeļa apmācība daudzvalodu datu kopā, kas ietver visas interesējošās valodas, un tā testēšana konkrētā valodā. Šī pieeja ir noderīga, ja paredzams, ka modelis dažādās valodās darbosies pietiekami labi un mērķis ir izveidot vienu nodomu noteikšanas modeli, kas spēj apstrādāt vairākas valodas. 

Vairāki pētījumi ir izmantojuši šo pieeju un parādījuši, ka tā var būt efektīva. Piemēram, autors (gads) pētīja modeļa apmācības efektivitāti daudzvalodu datu kopā, kas ietvēra (skaits) valodas: (valodu uzskaitījums), un testēja to noteiktā valodā. Rezultāti parādīja, ka modelis var sasniegt labu veiktspēju (\%) visās valodās. Līdzīgi autors (gads) izmantoja daudzvalodu datu kopu, kurā bija (skaits) valodas: (valodu uzskaitījums), un apmācīja nodomu noteikšanas modeli, kas sasniedza konkurētspējīgus rezultātus (valodu uzskaitījums) valodās. Tomēr šī pieeja var izraisīt zemāku precizitāti valodām, kurām ir mazāk apmācības piemēru. Savā pētījumā par daudzvalodu nodomu noteikšanu autors (gads) skaidroja, ka visu valodu apmācība kopā un konkrētas valodas testēšana var izraisīt šīs valodas precizitātes samazināšanos.

Priekšrocības ir mazākas modeļa apmācības izmaksas (viens modelis visiem datiem). Taču ir vairākas negatīvas sekas trenējot daudzvalodu jēdzientelpu modeli uz datu kopas, kurā kāda valoda, piemēram, angļu, ir disproporcionāli pārstāvēta (\textit{over represented}) un testējot uz maz-resursu (\textit{low-resource}) valodu, piemēram, latviešu. Pirmkārt, modelim var būt zemāka precizitāte latviešu valodā, kas nozīmē nepareizi klasificētus lietotāja nodomus un lietotāju neapmierinātību ar virtuālo asistentu. Otrkārt, modelis, kas trenēts uz disbalansētas datu kopas var ciest no katastrofiskas aizmiršanas (\textit{catastrophic interference}) fenomena, kurā modelis "aizmirst" maz-resursu valodu kad tiek iepazīstināts ar jauniem datiem citās valodās, kas noved pie zemas precizitātes un nepieciešamības pārtrenēt modeli. Šī darba kontekstā klasifikators ir uz 
Jābūt daudz pētījumu par šo, jo angļu valodas korpusi ir būtiski lielāki nekā citās valodās.


\section{Trenēšana angļu valodā, testēšana valodās, kas nav angļu}

Trešā pieeja ietver modeļa apmācību angļu valodā un tā testēšanu valodā, kas nav angļu valoda. Šī pieeja ir noderīga, ja ne-angļu valodām ir ierobežoti treniņkopas resursi un ja paredzams, ka modelis labi darbosies angļu valodā. Vairāki pētījumi ir izmantojuši šo pieeju un parādījuši, ka tā var būt efektīva, piemēram, autors (gads) izmantoja (datu kopa) datu kopu un parādīja, ka, apmācot nodomu noteikšanas modeli angļu valodā un testējot to (valoda) valodā, tika sasniegta līdzīga veiktspēja (\% precizitātes angļu, \% precizitāte citā valodā) ar modeļa apmācību (citā valodā) datu kopā. Tomēr šī pieeja paredz, ka valodu struktūra ir pietiekami līdzīga, lai modelis varētu pārnest zināšanas no angļu valodas uz citām valodām. Savā pētījumā par nodomu noteikšanu vairākās valodās autors (gads) atklāja, ka angļu valodas apmācība un citu valodu testēšana var izraisīt zemāku precizitāti, salīdzinot ar apmācību un testēšanu tajā pašā valodā.


\section{Mašīntulkošana uz angļu valodu}

Mašīntulkošana izvēlēta lai apietu šķērsli kurā maz-resursu valodās ir mazāk datu uz kā trenēt modeli. Ideja ir nevis gaidīt līdz tiks savākti pietiekami daudz datu, bet nodrošināt iespēju ienākt maz-resursu valodas lietotāju tirgū un sākt nodomu noteikšanu jau no pirmās dienas, lietotāju ievadus mašīntulkojot angļu valodā un izmantojot jau eksistējošos klasificēšanas modeļus angļu valodās. Kādu nepareizu nodomu noteikšanas \% pieļaut ir biznesa lēmums, bet tam arī nav jābūt 99.9\% vai nekas, jo iespējams lietot human-in-the-loop pieeju, kurā noteiktais nodoms pirms tikt padots lietotājam iziet caur klientu apkalpošanas speciālistu \cite{paikens2020}. Arī nepilna automatizācija ir noderīga, jo strādniekam novērtēt vaicājuma atbilstību konkrētam nodomam ir vieglāk (source) nekā izvērtēt kuram no daudziem nodomiem tas atbilst.

Taču mašīntulkošana rada papildu trokšņus un kļūdas, kas var ietekmēt ievades datu kvalitāti un klasifikācijas modeļu veiktspēju. Turklāt mašīntulkošanas rezultātā var tikt zaudētas svarīgas nianses un katrai valodai raksturīgā semantiskā informācija, kas var vēl vairāk pasliktināt ievades datu kvalitāti un apgrūtināt precīzu nodomu noteikšanu. Mani darbā interesē tieši noskaidrot pielietojamības robežas maz-resursu valodām un kādi trade-offs uzlabo modeļa precizitāti; šajā gadījumā vai modeļa veiktspēja ar mašīntulkošanas troksni atsver nepietiekamos datos. Tāpēc ir svarīgi novērtēt modeļu veiktspēju gan ar oriģinālajiem, gan mašīntulkotajiem ievades datiem un salīdzināt rezultātus, lai labāk izprastu modeļu stiprās puses un ierobežojumus daudzvalodu nodomu noteikšanas uzdevumos.