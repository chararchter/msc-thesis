@article{bengio2003,
    title={A neural probabilistic language model},
    author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
    journal={Journal of machine learning research},
    volume={3},
    number={Feb},
    pages={1137--1155},
    year={2003}
}

@article{word2vec2013,
    title={Efficient Estimation of Word Representations in Vector Space}, 
    author={Tom{\'{a}}s Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
    year={2013},
    month={Sep},
    eprinttype={arXiv},
    eprint={1301.3781},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/1301.3781v3}
}


@article{mikolov2013exploiting,
    title={Exploiting Similarities among Languages for Machine Translation},
    author={Tom{\'{a}}s Mikolov and Quoc V. Le and Ilya Sutskever},
    year={2013},
    month={Sep},
    eprinttype={arXiv},
    eprint={1309.4168},
    primaryClass={cs.CL},
    url={http://arxiv.org/abs/1309.4168}
}


@misc{parrish2017,
    title={Understanding word vectors},
    url={https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469},
    journal={Github},
    author={Parrish, Allison},
    year={2017},
    month={Apr}
}

@misc{colyer2016,
    title={The amazing power of word vectors},
    url={https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/},
    journal={the morning paper},
    author={Colyer, Adrian},
    year={2016},
    month={Apr}
}

@InProceedings{paikens2020,
    author="Paikens, P{\={e}}teris and Znoti{\c{n}}{\v{s}}, Art{\={u}}rs and B{\={a}}rzdi{\c{n}}{\v{s}}, Guntis",
    editor="M{\'e}tais, Elisabeth and Meziane, Farid and Horacek, Helmut and Cimiano, Philipp",
    title="Human-in-the-Loop Conversation Agent for Customer Service",
    booktitle="Natural Language Processing and Information Systems",
    year="2020",
    month={Jun},
    publisher="Springer International Publishing",
    address="Cham",
    pages="277--284",
    url={https://link.springer.com/chapter/10.1007/978-3-030-51310-8_25},
    doi={https://doi.org/10.1007/978-3-030-51310-8_25},
    abstract="This paper describes a prototype system for partial automation of customer service operations of a mobile telecommunications operator with a human-in-the loop conversational agent. The agent consists of an intent detection system for identifying the types of customer requests that it can handle appropriately, a slot filling information extraction system that integrates with the customer service database for a rule-based treatment of the common scenarios, and a template-based language generation system that builds response candidates that can be approved or amended by customer service operators. The main focus of this paper is on the system architecture and machine learning system structure design, and the observations of a limited pilot study performed to evaluate the proposed system on customer messages in Latvian. We also discuss the business requirements and practical application limitations and their influence on the design of the natural language processing components.",
    isbn="978-3-030-51310-8"
}

@misc{mccormick2016,
    title={Word2Vec Tutorial - The Skip-Gram Model},
    url={http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/},
    author={Chris McCormick},
    year={2016},
    month={Apr}
}

@article{fasttext2019,
    title={FastText-Based Intent Detection for Inflected Languages},
    author={Balodis, Kaspars and Deksne, Daiga},
    journal={Information},
    volume={10},
    year={2019},
    number={5:161},
    url={https://www.mdpi.com/2078-2489/10/5/161},
    issn={2078-2489},
    doi={10.3390/info10050161}
}


@incollection{nlp2018,
    title = {Chapter 3 - Open-Source Libraries, Application Frameworks, and Workflow Systems for NLP},
    editor = {Venkat N. Gudivada and C.R. Rao},
    series = {Handbook of Statistics},
    publisher = {Elsevier},
    volume = {38},
    pages = {31-50},
    year = {2018},
    booktitle = {Computational Analysis and Understanding of Natural Languages: Principles, Methods and Applications},
    issn = {0169-7161},
    doi = {https://doi.org/10.1016/bs.host.2018.07.007},
    url = {https://www.sciencedirect.com/science/article/pii/S0169716118300221},
    author = {Venkat N. Gudivada and Kamyar Arbabifard},
    keywords = {Natural language processing, Natural language understanding, Information retrieval, Open-source libraries, Workflow systems, Annotated corpora},
    abstract = {This chapter provides an annotated listing of various resources for natural language processing research and applications development. Resources include corpora, software libraries and frameworks, and workflow systems.}
}


@inproceedings{atis1990,
    title = "The {ATIS} Spoken Language Systems Pilot Corpus",
    author = "Hemphill, Charles T. and Godfrey, John J. and Doddington, George R.",
    booktitle = "Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley",
    year = "1990",
    url = "https://catalog.ldc.upenn.edu/docs/LDC93S4B/corpus.html",
}


@inproceedings{de-bruyn-2022,
    title = "Machine Translation for Multilingual Intent Detection and Slots Filling",
    author = "De bruyn, Maxime and Lotfi, Ehsan and Buhmann, Jeska and Daelemans, Walter",
    booktitle = "Proceedings of the Massively Multilingual Natural Language Understanding Workshop (MMNLU-22)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.mmnlu-1.8",
    pages = "69--82",
    abstract = "We expect to interact with home assistants irrespective of our language. However, scaling the Natural Language Understanding pipeline to multiple languages while keeping the same level of accuracy remains a challenge. In this work, we leverage the inherent multilingual aspect of translation models for the task of multilingual intent classification and slot filling. Our experiments reveal that they work equally well with general-purpose multilingual text-to-text models. Furthermore, their accuracy can be further improved by artificially increasing the size of the training set. Unfortunately, increasing the training set also increases the overlap with the test set, leading to overestimating their true capabilities. As a result, we propose two new evaluation methods capable of accounting for an overlap between the training and test set.",
}

@article{firdaus2023,
    title = {Multitask learning for multilingual intent detection and slot filling in dialogue systems},
    journal = {Information Fusion},
    volume = {91},
    pages = {299-315},
    year = {2023},
    issn = {1566-2535},
    doi = {https://doi.org/10.1016/j.inffus.2022.09.029},
    url = {https://www.sciencedirect.com/science/article/pii/S1566253522001671},
    author = {Mauajama Firdaus and Asif Ekbal and Erik Cambria},
    keywords = {Multitask learning, Multilingual analysis, Information fusion, Intent detection, Slot filling, Deep learning},
    abstract = {Dialogue systems are becoming an ubiquitous presence in our everyday lives having a huge impact on business and society. Spoken language understanding (SLU) is the critical component of every goal-oriented dialogue system or any conversational system. The understanding of the user utterance is crucial for assisting the user in achieving their desired objectives. Future-generation systems need to be able to handle the multilinguality issue. Hence, the development of conversational agents becomes challenging as it needs to understand the different languages along with the semantic meaning of the given utterance. In this work, we propose a multilingual multitask approach to fuse the two primary SLU tasks, namely, intent detection and slot filling for three different languages. While intent detection deals with identifying userâ€™s goal or purpose, slot filling captures the appropriate user utterance information in the form of slots. As both of these tasks are highly correlated, we propose a multitask strategy to tackle these two tasks concurrently. We employ a transformer as a shared sentence encoder for the three languages, i.e., English, Hindi, and Bengali. Experimental results show that the proposed model achieves an improvement for all the languages for both the tasks of SLU. The multi-lingual multi-task (MLMT) framework shows an improvement of more than 2% in case of intent accuracy and 3% for slot F1 score in comparison to the single task models. Also, there is an increase of more than 1 point intent accuracy and 2 points slot F1 score in the MLMT model as opposed to the language specific frameworks.}
}

@inproceedings{jayarao2018,
    author={Jayarao, Pratik and Srivastava, Aman},
    booktitle={2018 International Conference on Electrical, Electronics, Communication, Computer, and Optimization Techniques (ICEECCOT)}, 
    title={Intent Detection for code-mix utterances in task oriented dialogue systems}, 
    year={2018},
    volume={},
    number={},
    pages={583-587},
    doi={10.1109/ICEECCOT43722.2018.9001577}
}


@article{liu2020,
    title={Attention-Informed Mixed-Language Training for Zero-Shot Cross-Lingual Task-Oriented Dialogue Systems},
    volume={34},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/6362},
    DOI={10.1609/aaai.v34i05.6362},
    number={05},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    author={Liu, Zihan and Winata, Genta Indra and Lin, Zhaojiang and Xu, Peng and Fung, Pascale},
    year={2020},
    month={Apr.},
    pages={8433-8440}
}